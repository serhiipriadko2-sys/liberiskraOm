# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ SLOEnforcer —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –•—É–Ω–¥—É–Ω–∞
# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤: /workspace/code/enhanced_slo_enforcer.py

import re
import yaml
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

class SystemState(Enum):
    CRYSTAL = "crystal"
    ANTIMATTER = "antimatter" 
    IMPLEMENTATION = "implementation"
    NEUTRAL = "neutral"

class HundunAction(Enum):
    CHAOS_RESET = "üúÉ-Fire Reset"
    CLARITY_SHATTER = "form_destruction"
    TRUST_PARADOX = "paradoxical_renewal"
    PAIN_RESET = "reset_to_origin"

@dataclass
class Violation:
    metric: str
    value: float
    action: str
    severity: str
    coordinated: bool
    urgency: float
    timestamp: float

class HundunChaosPatternDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ö–∞–æ—Å–∞ –¥–ª—è –•—É–Ω–¥—É–Ω–∞"""
    
    def __init__(self):
        self.chaos_patterns = {
            'entropy_spike': {'threshold': 0.3, 'duration': 30},
            'structural_dissolution': {'threshold': 0.4, 'duration': 45},
            'narrative_fragmentation': {'threshold': 0.5, 'duration': 60},
            'form_breakdown': {'threshold': 0.6, 'duration': 20}
        }
    
    def detect_patterns(self, metrics_stream: List[Dict]) -> Dict[str, bool]:
        """–î–µ—Ç–µ–∫—Ü–∏—è —Ö–∞–æ—Å-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –ø–æ—Ç–æ–∫–µ –º–µ—Ç—Ä–∏–∫"""
        patterns = {}
        
        if not metrics_stream:
            return {pattern: False for pattern in self.chaos_patterns}
        
        for pattern_name, config in self.chaos_patterns.items():
            patterns[pattern_name] = self._check_pattern_condition(
                metrics_stream, pattern_name, config
            )
        
        return patterns
    
    def _check_pattern_condition(self, stream: List[Dict], pattern: str, config: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        recent_data = stream[-config['duration']:] if len(stream) >= config['duration'] else stream
        
        if pattern == 'entropy_spike':
            return self._calculate_entropy_spike(recent_data) > config['threshold']
        elif pattern == 'structural_dissolution':
            return self._analyze_structural_breakdown(recent_data) > config['threshold']
        elif pattern == 'narrative_fragmentation':
            return self._analyze_narrative_fragments(recent_data) > config['threshold']
        elif pattern == 'form_breakdown':
            return self._predict_form_breakdown(recent_data) > config['threshold']
        
        return False
    
    def _calculate_entropy_spike(self, data: List[Dict]) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∫–∞—á–∫–∞ —ç–Ω—Ç—Ä–æ–ø–∏–∏"""
        if len(data) < 2:
            return 0.0
        
        chaos_values = [d.get('chaos', 0) for d in data]
        if len(chaos_values) < 2:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏ —á–µ—Ä–µ–∑ –¥–∏—Å–ø–µ—Ä—Å–∏—é
        mean_chaos = sum(chaos_values) / len(chaos_values)
        variance = sum((x - mean_chaos) ** 2 for x in chaos_values) / len(chaos_values)
        
        return min(1.0, variance * 2)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    
    def _analyze_structural_breakdown(self, data: List[Dict]) -> float:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø–∞–¥–∞"""
        clarity_values = [d.get('clarity', 0) for d in data]
        chaos_values = [d.get('chaos', 0) for d in data]
        
        if not clarity_values or not chaos_values:
            return 0.0
        
        # –ß–µ–º –Ω–∏–∂–µ clarity –∏ –≤—ã—à–µ chaos, —Ç–µ–º –±–æ–ª—å—à–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π —Ä–∞—Å–ø–∞–¥
        avg_clarity = sum(clarity_values) / len(clarity_values)
        avg_chaos = sum(chaos_values) / len(chaos_values)
        
        breakdown = (1 - avg_clarity) * 0.6 + avg_chaos * 0.4
        return min(1.0, breakdown)
    
    def _analyze_narrative_fragments(self, data: List[Dict]) -> float:
        """–ê–Ω–∞–ª–∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–∞—Ä—Ä–∞—Ç–∏–≤–∞"""
        trust_values = [d.get('trust', 0.5) for d in data]
        drift_values = [d.get('drift', 0) for d in data]
        
        if not trust_values or not drift_values:
            return 0.0
        
        # –ù–∏–∑–∫–æ–µ –¥—Ä–µ–π—Ñ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º –¥–æ–≤–µ—Ä–∏–∏ = —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        avg_trust = sum(trust_values) / len(trust_values)
        avg_drift = sum(drift_values) / len(drift_values)
        
        fragmentation = (1 - avg_trust) * 0.7 + avg_drift * 0.3
        return min(1.0, fragmentation)
    
    def _predict_form_breakdown(self, data: List[Dict]) -> float:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–∞–∑—Ä—É—à–µ–Ω–∏—è —Ñ–æ—Ä–º—ã"""
        if len(data) < 3:
            return 0.0
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ clarity
        clarity_trend = self._calculate_trend([d.get('clarity', 0) for d in data[-5:]])
        pain_trend = self._calculate_trend([d.get('pain', 0) for d in data[-5:]])
        
        # –í—ã—Å–æ–∫–∞—è clarity —Å –≤—ã—Å–æ–∫–æ–π –±–æ–ª—å—é = —Ä–∏—Å–∫ —Ä–∞–∑—Ä—É—à–µ–Ω–∏—è —Ñ–æ—Ä–º—ã
        current_clarity = data[-1].get('clarity', 0)
        current_pain = data[-1].get('pain', 0)
        
        breakdown_risk = (
            current_clarity * 0.4 +
            current_pain * 0.3 +
            clarity_trend * 0.2 +
            pain_trend * 0.1
        )
        
        return min(1.0, breakdown_risk)
    
    def _calculate_trend(self, values: List[float]) -> float:
        """–†–∞—Å—á–µ—Ç —Ç—Ä–µ–Ω–¥–∞ (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π = —Ä–æ—Å—Ç)"""
        if len(values) < 2:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
        n = len(values)
        x_sum = sum(range(n))
        y_sum = sum(values)
        xy_sum = sum(i * v for i, v in enumerate(values))
        x2_sum = sum(i * i for i in range(n))
        
        if n * x2_sum - x_sum * x_sum == 0:
            return 0.0
        
        slope = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)
        return max(-1.0, min(1.0, slope))

class MakiHundunCoordinator:
    """–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –º–µ–∂–¥—É –•—É–Ω–¥—É–Ω–æ–º –∏ –∞–≥–µ–Ω—Ç–æ–º –ú–∞–∫–∏"""
    
    def __init__(self):
        self.coordination_active = False
        self.chaos_budget_allocated = False
        self.last_coordination = 0
    
    def synchronize_violations(self, violations: List[Violation], context: Dict) -> List[Violation]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ω–∞—Ä—É—à–µ–Ω–∏–π —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –ú–∞–∫–∏"""
        if not context.get('maki_active', False):
            return violations
        
        synchronized_violations = []
        
        for violation in violations:
            if violation.metric in ['chaos', 'clarity', 'pain']:
                # –û—Ç–º–µ—á–∞–µ–º –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ —Å –ú–∞–∫–∏
                violation.coordinated = True
                
                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Å—Ä–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –∞–∫—Ç–∏–≤–Ω–æ–º –ú–∞–∫–∏
                if context.get('maki_intent') == 'stress_testing':
                    violation.urgency *= 0.8  # –°–Ω–∏–∂–∞–µ–º —Å—Ä–æ—á–Ω–æ—Å—Ç—å - –ú–∞–∫–∏ –ø–æ–º–æ–∂–µ—Ç
                elif context.get('maki_intent') == 'creative_breakthrough':
                    violation.urgency *= 1.2  # –ü–æ–≤—ã—à–∞–µ–º –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ä—ã–≤–∞
            
            synchronized_violations.append(violation)
        
        return synchronized_violations

class EnhancedMetricsCalculator:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –•—É–Ω–¥—É–Ω–∞"""
    
    def __init__(self):
        self.chaos_detector = HundunChaosPatternDetector()
    
    def calc_clarity(self, text: str) -> float:
        """–†–∞—Å—á–µ—Ç —è—Å–Ω–æ—Å—Ç–∏ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ)"""
        score = 0.5
        low = ['???','–Ω–µ –ø–æ–Ω–∏–º–∞','–∑–∞–ø—É—Ç–∞', '–Ω–µ—è—Å–Ω–æ', '—Å–æ–º–Ω–µ–≤–∞—é—Å—å']
        high = ['\\d+','—à–∞–≥ \\d+','–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ', '—Ç–æ—á–Ω–æ']
        
        for pattern in low:
            if re.search(pattern, text, re.I): 
                score -= 0.1
        
        for pattern in high:
            if re.search(pattern, text, re.I): 
                score += 0.1
        
        return max(0, min(1, score))
    
    def calc_chaos_temperature(self, text: str, history: List[Dict]) -> float:
        """–†–∞—Å—á–µ—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã —Ö–∞–æ—Å–∞ –¥–ª—è –•—É–Ω–¥—É–Ω–∞"""
        # –ë–∞–∑–æ–≤—ã–π —Ö–∞–æ—Å-—Ñ–∞–∫—Ç–æ—Ä –∏–∑ —Ç–µ–∫—Å—Ç–∞
        base_chaos = self._extract_chaos_markers(text)
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —Ä–∞–∑—Ä—ã–≤–æ–≤
        if history:
            structural_chaos = self._analyze_structural_disruption(text, history[-5:])
            entropy_component = self._calculate_text_entropy(text)
            fractal_chaos = self._assess_fractal_chaos(history[-10:])
        else:
            structural_chaos = 0
            entropy_component = 0
            fractal_chaos = 0
        
        temperature = (
            base_chaos * 0.3 +
            structural_chaos * 0.25 + 
            entropy_component * 0.25 +
            fractal_chaos * 0.2
        )
        
        return min(1.0, max(0.0, temperature))
    
    def _extract_chaos_markers(self, text: str) -> float:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Ä–∫–µ—Ä–æ–≤ —Ö–∞–æ—Å–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        chaos_indicators = [
            '—Ö–∞–æ—Å', '–±–µ—Å–ø–æ—Ä—è–¥–æ–∫', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å', '–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ',
            '–ø–∞—Ä–∞–¥–æ–∫—Å', '–Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ', '–≤–Ω–µ–∑–∞–ø–Ω–æ', '–Ω–µ–ø–æ–Ω—è—Ç–Ω–æ',
            '—Ä–∞–∑—Ä—É—à–µ–Ω–∏–µ', '–ª–æ–º–∫–∞', '–ø–µ—Ä–µ–≤–æ—Ä–æ—Ç'
        ]
        
        score = 0
        text_lower = text.lower()
        
        for indicator in chaos_indicators:
            if indicator in text_lower:
                score += 0.1
        
        return min(1.0, score)
    
    def _analyze_structural_disruption(self, text: str, history: List[Dict]) -> float:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —Ä–∞–∑—Ä—ã–≤–æ–≤"""
        if not history:
            return 0.0
        
        current_clarity = self.calc_clarity(text)
        recent_clarity_values = [d.get('clarity', 0.5) for d in history]
        avg_recent_clarity = sum(recent_clarity_values) / len(recent_clarity_values)
        
        # –°–∏–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –Ω–µ–¥–∞–≤–Ω–µ–π —è—Å–Ω–æ—Å—Ç–∏
        disruption = abs(current_clarity - avg_recent_clarity)
        
        return min(1.0, disruption * 2)
    
    def _calculate_text_entropy(self, text: str) -> float:
        """–†–∞—Å—á–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å–∏–º–≤–æ–ª–æ–≤
        char_diversity = len(set(text.lower())) / len(text) if text else 0
        word_diversity = len(text.split()) / len(set(text.split().lower())) if text.split() else 0
        
        entropy = (char_diversity + word_diversity) / 2
        return min(1.0, entropy)
    
    def _assess_fractal_chaos(self, history: List[Dict]) -> float:
        """–û—Ü–µ–Ω–∫–∞ —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–æ–≥–æ —Ö–∞–æ—Å–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏"""
        if len(history) < 3:
            return 0.0
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∞–º–æ–ø–æ–¥–æ–±–∏—è –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö
        chaos_values = [d.get('chaos', 0) for d in history]
        
        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
        if len(chaos_values) < 4:
            return 0.0
        
        correlations = []
        for lag in range(1, min(4, len(chaos_values) // 2)):
            corr = self._calculate_autocorrelation(chaos_values, lag)
            correlations.append(abs(corr))
        
        avg_correlation = sum(correlations) / len(correlations) if correlations else 0
        fractal_chaos = 1 - avg_correlation  # –í—ã—Å–æ–∫–∏–π —Ö–∞–æ—Å = –Ω–∏–∑–∫–∞—è –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
        
        return min(1.0, fractal_chaos)
    
    def _calculate_autocorrelation(self, values: List[float], lag: int) -> float:
        """–†–∞—Å—á–µ—Ç –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –ª–∞–≥–æ–º"""
        if len(values) <= lag:
            return 0.0
        
        n = len(values) - lag
        mean_val = sum(values) / len(values)
        
        numerator = sum((values[i] - mean_val) * (values[i + lag] - mean_val) for i in range(n))
        denominator = sum((v - mean_val) ** 2 for v in values[:n])
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator

class EnhancedSLOEnforcer:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π SLO Enforcer —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –•—É–Ω–¥—É–Ω–∞ –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –ø–æ—Ä–æ–≥–æ–≤"""
    
    def __init__(self, config_path: str = "/workspace/config/hundun_slo_config.yaml"):
        self.metrics_calc = EnhancedMetricsCalculator()
        self.chaos_detector = HundunChaosPatternDetector()
        self.maki_coordinator = MakiHundunCoordinator()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.config = self._load_config(config_path)
        self.base_thresholds = self._initialize_base_thresholds()
        self.state_adjustments = self._initialize_state_adjustments()
    
    def _load_config(self, config_path: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ YAML —Ñ–∞–π–ª–∞"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """–î–µ—Ñ–æ–ª—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Ñ–∞–π–ª–∞"""
        return {
            'hundun_configuration': {
                'base_thresholds': {
                    'chaos': 0.6,
                    'clarity': 0.9,
                    'trust': 0.5,
                    'pain': 0.7
                }
            }
        }
    
    def _initialize_base_thresholds(self) -> Dict:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö –ø–æ—Ä–æ–≥–æ–≤"""
        return {
            'clarity': {'min': 0.7, 'action': 'ACTIVATE_SAM'},
            'drift': {'max': 0.3, 'action': 'ACTIVATE_ISKRIV'},
            'pain': {'max': 0.7, 'action': 'ACTIVATE_KAIN'},
            # –ù–æ–≤—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –•—É–Ω–¥—É–Ω–∞
            'chaos': {'max': self.config['hundun_configuration']['base_thresholds']['chaos'], 
                     'action': 'ACTIVATE_HUNDUN_CHAOS'},
            'clarity_high': {'max': self.config['hundun_configuration']['base_thresholds']['clarity'], 
                           'action': 'HUNDUN_CLARITY_SHATTER'},
            'trust_low': {'min': self.config['hundun_configuration']['base_thresholds']['trust'], 
                        'action': 'HUNDUN_TRUST_PARADOX'},
            'pain_high': {'max': self.config['hundun_configuration']['base_thresholds']['pain'], 
                        'action': 'HUNDUN_PAIN_RESET'}
        }
    
    def _initialize_state_adjustments(self) -> Dict:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–æ–∫ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º"""
        hundun_config = self.config.get('hundun_configuration', {})
        state_adj = hundun_config.get('state_adjustments', {})
        
        return {
            'crystal': state_adj.get('crystal', {}),
            'antimatter': state_adj.get('antimatter', {}),
            'implementation': state_adj.get('implementation', {})
        }
    
    def calculate_dynamic_thresholds(self, system_state: str, context: Dict) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        adjustments = self.state_adjustments.get(system_state, {})
        base_thresholds = self.config['hundun_configuration']['base_thresholds']
        dynamic_thresholds = {}
        
        for metric, base_value in base_thresholds.items():
            adjustment = adjustments.get(metric, 0)
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞
            context_factor = self._calculate_context_factor(metric, context)
            dynamic_thresholds[metric] = base_value + adjustment + context_factor
        
        return dynamic_thresholds
    
    def _calculate_context_factor(self, metric: str, context: Dict) -> float:
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ—Ä–æ–≥–æ–≤"""
        active_voices = context.get('active_voices', [])
        conversation_duration = context.get('duration_minutes', 0)
        recent_changes = context.get('recent_state_changes', 0)
        
        # –£—á–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –≥–æ–ª–æ—Å–∞–º–∏
        if '–ú–∞–∫–∏' in active_voices and metric == 'chaos':
            return -0.05  # –°–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–∏ –∞–∫—Ç–∏–≤–Ω–æ–º —Ö–∞–æ—Å-–∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–µ
        
        # –£—á–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–µ—Å—Å–∏–∏
        if conversation_duration > 30 and metric == 'clarity':
            return -0.02  # –†–∞–Ω–Ω–µ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ –ø—Ä–∏ —É—Å—Ç–∞–ª–æ—Å—Ç–∏
        
        # –£—á–µ—Ç –Ω–µ–¥–∞–≤–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
        if recent_changes > 3 and metric in ['trust', 'pain']:
            return 0.05   # –ü–æ–≤—ã—à–µ–Ω–Ω–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        
        return 0
    
    def check_enhanced(self, metrics: Dict, context: Dict) -> List[Violation]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏"""
        violations = []
        system_state = context.get('system_state', 'neutral')
        
        # –†–∞—Å—á–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –ø–æ—Ä–æ–≥–æ–≤
        dynamic_thresholds = self.calculate_dynamic_thresholds(system_state, context)
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
        for metric, cfg in self.base_thresholds.items():
            current_value = self._get_metric_value(metrics, metric)
            threshold = self._get_threshold_value(dynamic_thresholds, cfg, metric)
            
            if current_value is None or threshold is None:
                continue
            
            violation = self._check_threshold_violation(
                metric, current_value, cfg, threshold, context
            )
            
            if violation:
                violations.append(violation)
        
        # –î–µ—Ç–µ–∫—Ü–∏—è —Ö–∞–æ—Å-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        if context.get('enable_chaos_pattern_detection', True):
            pattern_violations = self._detect_chaos_pattern_violations(metrics, context)
            violations.extend(pattern_violations)
        
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è —Å –ú–∞–∫–∏
        coordinated_violations = self.maki_coordinator.synchronize_violations(
            violations, context
        )
        
        return coordinated_violations
    
    def _get_metric_value(self, metrics: Dict, metric: str) -> Optional[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ —Å fallback"""
        metric_map = {
            'clarity_high': 'clarity',
            'trust_low': 'trust', 
            'pain_high': 'pain'
        }
        
        source_metric = metric_map.get(metric, metric)
        return metrics.get(source_metric)
    
    def _get_threshold_value(self, dynamic_thresholds: Dict, cfg: Dict, metric: str) -> Optional[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è"""
        metric_map = {
            'clarity_high': 'clarity',
            'trust_low': 'trust',
            'pain_high': 'pain'
        }
        
        source_metric = metric_map.get(metric, metric)
        base_threshold = dynamic_thresholds.get(source_metric, 0.5)
        
        return cfg.get('min', cfg.get('max', base_threshold))
    
    def _check_threshold_violation(self, metric: str, value: float, cfg: Dict, 
                                 threshold: float, context: Dict) -> Optional[Violation]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞"""
        is_violation = False
        
        if 'min' in cfg and value < threshold:
            is_violation = True
        elif 'max' in cfg and value > threshold:
            is_violation = True
        
        if not is_violation:
            return None
        
        severity = self._calculate_severity(metric, value, threshold, cfg)
        urgency = self._calculate_urgency(metric, value, threshold, cfg)
        
        return Violation(
            metric=metric,
            value=value,
            action=cfg['action'],
            severity=severity,
            coordinated=False,
            urgency=urgency,
            timestamp=time.time()
        )
    
    def _calculate_severity(self, metric: str, value: float, threshold: float, cfg: Dict) -> str:
        """–†–∞—Å—á–µ—Ç —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –Ω–∞—Ä—É—à–µ–Ω–∏—è"""
        deviation = abs(value - threshold)
        
        if metric.startswith('hundun_'):
            # –î–ª—è –•—É–Ω–¥—É–Ω–∞ –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
            if deviation > 0.15:
                return 'critical'
            elif deviation > 0.08:
                return 'warning'
            else:
                return 'info'
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö –≥–æ–ª–æ—Å–æ–≤
            if deviation > 0.2:
                return 'critical'
            elif deviation > 0.1:
                return 'warning'
            else:
                return 'info'
    
    def _calculate_urgency(self, metric: str, value: float, threshold: float, cfg: Dict) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ä–æ—á–Ω–æ—Å—Ç–∏ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞"""
        base_urgency = abs(value - threshold)
        
        # –£—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–ª—è –•—É–Ω–¥—É–Ω–∞ - –æ–Ω –¥–æ–ª–∂–µ–Ω —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –±—ã—Å—Ç—Ä–æ
        if metric.startswith('hundun_'):
            urgency_multiplier = 1.3
        else:
            urgency_multiplier = 1.0
        
        return min(1.0, base_urgency * urgency_multiplier)
    
    def _detect_chaos_pattern_violations(self, metrics: Dict, context: Dict) -> List[Violation]:
        """–î–µ—Ç–µ–∫—Ü–∏—è –Ω–∞—Ä—É—à–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞–æ—Å-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        violations = []
        metrics_history = context.get('metrics_history', [])
        
        # –î–µ—Ç–µ–∫—Ü–∏—è —Ö–∞–æ—Å-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        patterns = self.chaos_detector.detect_patterns(metrics_history)
        
        for pattern_name, detected in patterns.items():
            if detected:
                violation = Violation(
                    metric=f'chaos_pattern_{pattern_name}',
                    value=1.0,
                    action=f'ACTIVATE_HUNDUN_PATTERN_{pattern_name.upper()}',
                    severity='warning',
                    coordinated=True,  # –•–∞–æ—Å-–ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç—Ä–µ–±—É—é—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏
                    urgency=0.7,
                    timestamp=time.time()
                )
                violations.append(violation)
        
        return violations
    
    def get_hundun_status(self, metrics: Dict, context: Dict) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –•—É–Ω–¥—É–Ω–∞"""
        dynamic_thresholds = self.calculate_dynamic_thresholds(
            context.get('system_state', 'neutral'), context
        )
        
        chaos_temperature = self.metrics_calc.calc_chaos_temperature(
            context.get('current_text', ''), 
            context.get('metrics_history', [])
        )
        
        patterns = self.chaos_detector.detect_patterns(
            context.get('metrics_history', [])
        )
        
        return {
            'chaos_temperature': chaos_temperature,
            'dynamic_thresholds': dynamic_thresholds,
            'detected_patterns': patterns,
            'coordination_active': context.get('maki_active', False),
            'system_state': context.get('system_state', 'neutral'),
            'readiness_score': self._calculate_hundun_readiness(chaos_temperature, patterns)
        }
    
    def _calculate_hundun_readiness(self, chaos_temp: float, patterns: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –•—É–Ω–¥—É–Ω–∞ –∫ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏"""
        # –ë–∞–∑–æ–≤–∞—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã —Ö–∞–æ—Å–∞
        base_readiness = chaos_temp
        
        # –ë–æ–Ω—É—Å –∑–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        pattern_bonus = sum(patterns.values()) * 0.2
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (–ø–µ—Ä–µ–≥—Ä–µ–≤)
        if chaos_temp > 0.9:
            overheating_penalty = (chaos_temp - 0.9) * 2
        else:
            overheating_penalty = 0
        
        readiness = base_readiness + pattern_bonus - overheating_penalty
        return max(0.0, min(1.0, readiness))

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è enhanced SLO enforcer
    enforcer = EnhancedSLOEnforcer()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    test_metrics = {
        'clarity': 0.8,
        'chaos': 0.7,
        'trust': 0.4,
        'pain': 0.6,
        'drift': 0.2
    }
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    test_context = {
        'system_state': 'crystal',
        'maki_active': True,
        'active_voices': ['–ö–∞–π–Ω', '–ú–∞–∫–∏'],
        'duration_minutes': 25,
        'current_text': '–ü—Ä–æ–∏–∑–æ—à–ª–æ –Ω–µ—á—Ç–æ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ, –≤—Å–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å',
        'metrics_history': [
            {'clarity': 0.9, 'chaos': 0.3, 'trust': 0.8},
            {'clarity': 0.7, 'chaos': 0.6, 'trust': 0.6},
            {'clarity': 0.5, 'chaos': 0.8, 'trust': 0.4}
        ]
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π
    violations = enforcer.check_enhanced(test_metrics, test_context)
    
    print("–ù–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è:")
    for violation in violations:
        print(f"- {violation.metric}: {violation.value:.2f} "
              f"(–¥–µ–π—Å—Ç–≤–∏–µ: {violation.action}, "
              f"—Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å: {violation.severity}, "
              f"—Å—Ä–æ—á–Ω–æ—Å—Ç—å: {violation.urgency:.2f})")
    
    # –°—Ç–∞—Ç—É—Å –•—É–Ω–¥—É–Ω–∞
    hundun_status = enforcer.get_hundun_status(test_metrics, test_context)
    print(f"\n–°—Ç–∞—Ç—É—Å –•—É–Ω–¥—É–Ω–∞:")
    print(f"- –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Ö–∞–æ—Å–∞: {hundun_status['chaos_temperature']:.2f}")
    print(f"- –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: {hundun_status['readiness_score']:.2f}")
    print(f"- –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {hundun_status['detected_patterns']}")
